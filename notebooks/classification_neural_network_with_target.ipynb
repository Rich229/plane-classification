{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Imort needed packages\n",
    "\n",
    "import datetime\n",
    "import pathlib\n",
    "import yaml\n",
    "\n",
    "from matplotlib.colors import ListedColormap\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, Dense, Flatten, Dropout\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load constantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"config.yaml\",'r') as config_file:\n",
    "    config = yaml.safe_load(config_file)\n",
    "    IMAGE_WIDTH = config[\"image_width\"]\n",
    "    IMAGE_HEIGHT = config[\"image_height\"]\n",
    "    IMAGE_DEPTH = config[\"image_depth\"]\n",
    "    DATA_DIR= pathlib.Path(config[\"data_dir\"])\n",
    "    MODELS_DIR = pathlib.Path(config[\"models_dir\"])\n",
    "    TARGET_NAME= config[\"target_name\"]\n",
    "    DATA_TRAIN_FILE= config[\"data_train_file\"]\n",
    "    DATA_TEST_FILE= config[\"data_test_file\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_image_database(path,target):\n",
    "    \"\"\"    Build a pandas dataframe with target class and access path to images.\n",
    "\n",
    "    Parameters:\n",
    "        - path (Path): Path pattern to read csv file containing images information\n",
    "        - target(str): The second column to extract from the file\n",
    "\n",
    "    Return:\n",
    "        A pandas dataframe,\n",
    "    -------\n",
    "    \"\"\"\n",
    "    #Load file\n",
    "    _df= pd.read_csv(path,\n",
    "            names=[\"all\"],\n",
    "        )\n",
    "    #Recover data\n",
    "    _df[\"image_id\"]=_df[\"all\"].apply(lambda x: x.split(' ')[0])\n",
    "    _df[target]=_df[\"all\"].apply(lambda x: ' '.join(x.split(' ')[1:]))\n",
    "    _df[target].unique()\n",
    "\n",
    "    #Create path\n",
    "    _df[\"path\"]= _df['image_id'].apply( lambda x: DATA_DIR/\"images\"/(x+'.jpg')) \n",
    "    \n",
    "    return _df.drop(columns=[\"all\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_classification_model(df: pd.DataFrame,target: str, images: str):\n",
    "    \"\"\"Build a tensorflow model using information from target and images columns in dataframes\n",
    "    Parameters\n",
    "    ----------\n",
    "        df (pandas.dataFrame): dataframe with target and images columns\n",
    "        target (str): column name for target variable\n",
    "        images (str): column name for images\n",
    "    Returns\n",
    "    ------\n",
    "    tensorflow model built & compiled\n",
    "    \"\"\"\n",
    "    \n",
    "    #Compute number of classes for output layer\n",
    "    nb_classes = df[target].nunique()\n",
    "    \n",
    "    # Computer images size for input layer\n",
    "    size = df[images].iloc[0].shape\n",
    "    \n",
    "    # Building the model\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(filters=32, kernel_size=(5,5), activation='relu', input_shape=size))\n",
    "    model.add(Conv2D(filters=32, kernel_size=(5,5), activation='relu'))\n",
    "    model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(rate=0.25))\n",
    "    model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(rate=0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(rate=0.5))\n",
    "    model.add(Dense(nb_classes , activation='softmax'))\n",
    "\n",
    "    #Compilation of the model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy']) #output layer of nb_classes\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image(df,row,target):\n",
    "    \"\"\"show the image in the ligne row and the associated target column\n",
    "\n",
    "    Args:\n",
    "        df (pandas.dataFrame): the dataframe of images\n",
    "        row (int): the index of the row\n",
    "        target (string): the column name of the associated label\n",
    "    Return\n",
    "    ------\n",
    "    None\n",
    "    \"\"\"\n",
    "\n",
    "    assert target in df.columns, f\"Column {target} not found in dataframe\"\n",
    "    assert 'path' in df.columns, f\"Column path doens't not exit in dataframe\"\n",
    "    _img = plt.imread(df.loc[row,'path'])\n",
    "    plt.imshow(_img)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_resize_image(path,height,width):\n",
    "    \"\"\"Load an image and resize it to the target size\n",
    "\n",
    "    Parameters:\n",
    "        - path (Path): path to the file to load and resize\n",
    "        - height (int): the height of the final resized image\n",
    "        - width(int): the width of the resized image \n",
    "    Return\n",
    "    ------\n",
    "    numpy.array containing resized image\n",
    "    \"\"\"\n",
    "    return np.array(Image.open(path).resize((width,height)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_x_and_y(df: pd.DataFrame, target: str, images: str):\n",
    "    \"\"\"build x tensor and y tensor for model fitting.\n",
    "    parameters\n",
    "    ----------\n",
    "    df(pd.DataFrame): dataframe \n",
    "    target(str): name of target column\n",
    "    images (str): name of resized images column\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    \n",
    "    x (numpy.array): tensor of x values\n",
    "    y (numpy.array): tensor of y values\n",
    "    \"\"\"\n",
    "    \n",
    "    x= np.array(df[images].to_list())\n",
    "    y=tf.keras.utils.to_categorical(df[target].astype('category').cat.codes)\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_images(images,model,classes_names=None):\n",
    "    \"\"\"Classify images through a tensorflow model.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    images(np.array): set of images to classify\n",
    "    model (tensorflow.keras.Model): tensorflow/keras model\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    predicted classes \n",
    "    \n",
    "    \"\"\"\n",
    "    results = model.predict(images)\n",
    "    classes = np.argmax(results,axis=1)\n",
    "    if classes_names is not None:\n",
    "        classes = np.array(classes_names[classes])\n",
    "    return classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model ,saving_dir=MODELS_DIR,basename=TARGET_NAME,append_time=False):\n",
    "    \"\"\"Save tf/Keras model in saving_dir folder\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model (tf/Keras model): model to be saved\n",
    "    saving_dir (path): location to save model file\n",
    "    basename (str): the basename of the model\n",
    "    append_time (bool): indicate if the time will be append to the basename\n",
    "    \"\"\"\n",
    "    model_name = f\"{basename}{'_' + datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S') if append_time   else ''}\"\n",
    "    model.save(f\"{saving_dir}/neural_networks/{model_name}.h5\")\n",
    "    return model_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read train & test file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = build_image_database(DATA_DIR/DATA_TRAIN_FILE,TARGET_NAME)\n",
    "test_df = build_image_database(DATA_DIR/DATA_TEST_FILE,TARGET_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Previous the dataframe \n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# View some images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(train_df, np.random.randint(0,train_df.shape[0]), TARGET_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(test_df,np.random.randint(0,test_df.shape[0]),TARGET_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resize Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Resize train images\n",
    "train_df['resized_image'] = train_df.apply(\n",
    "        lambda r: load_resize_image(r['path'],IMAGE_HEIGHT,IMAGE_WIDTH),\n",
    "        axis=1)\n",
    "#Resize test images\n",
    "test_df['resized_image'] = test_df.apply(\n",
    "    lambda r: load_resize_image(r['path'],IMAGE_HEIGHT,IMAGE_WIDTH),\n",
    "    axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split dataset into x and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,y_train = build_x_and_y(train_df,TARGET_NAME,'resized_image')\n",
    "X_test,y_test = build_x_and_y(test_df,TARGET_NAME,'resized_image')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build & train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_classification_model(train_df,TARGET_NAME,\"resized_image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "\n",
    "!rm -rf ./logs\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "epochs = 5\n",
    "history = model.fit(X_train,y_train,batch_size = 32,epochs = epochs , validation_data = (X_test,y_test),\n",
    "                   callbacks=[tensorboard_callback]\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard  --logdir  logs/fit "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict from the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_names = train_df[TARGET_NAME].astype('category').cat.categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classify_images(X_test[10:20],model,classes_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = save_model(model,MODELS_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(MODELS_DIR/\"classes\"/f\"{model_name}.yaml\",\"w\") as classe_file:\n",
    "    yaml.dump(list(classes_names),classe_file)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c0c62eb8809ce627d066c8fbd0f39db2e3615da8e58a6548a8d5314d7610383d"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
