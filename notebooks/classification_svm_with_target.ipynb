{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import needed packages\n",
    "\n",
    "import datetime\n",
    "import pathlib\n",
    "import yaml\n",
    "\n",
    "#from matplotlib.colors import ListedColormap\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OrdinalEncoder \n",
    "from sklearn import svm \n",
    "from sklearn.metrics import accuracy_score\n",
    "import tensorflow as tf\n",
    "\n",
    "import pickle\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load constantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"config.yaml\",'r') as config_file:\n",
    "    config = yaml.safe_load(config_file)\n",
    "    IMAGE_WIDTH = config[\"image_width\"]\n",
    "    IMAGE_HEIGHT = config[\"image_height\"]\n",
    "    IMAGE_DEPTH = config[\"image_depth\"]\n",
    "    DATA_DIR= pathlib.Path(config[\"data_dir\"])\n",
    "    MODELS_DIR = pathlib.Path(config[\"models_dir\"])\n",
    "    TARGET_NAME= config[\"target_name\"]\n",
    "    DATA_TRAIN_FILE= config[\"data_train_file\"]\n",
    "    DATA_TEST_FILE= config[\"data_test_file\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_resize_image(path,height,width):\n",
    "    \"\"\"Load an image and resize it to the target size\n",
    "\n",
    "    Parameters:\n",
    "        path (Path): path to the file to load and resize\n",
    "        height (int): the height of the final resized image\n",
    "        width(int): the width of the resized image \n",
    "    Return\n",
    "    ------\n",
    "    numpy.array containing resized image\n",
    "    \"\"\"\n",
    "    return np.array(Image.open(path).resize((width,height)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_x_and_y(df: pd.DataFrame, target: str, images: str,encoder):\n",
    "    \"\"\"build x tensor and y tensor for model fitting.\n",
    "    parameters\n",
    "    ----------\n",
    "    df(pd.DataFrame): dataframe \n",
    "    target(str): name of target column\n",
    "    images (str): name of resized images column\n",
    "    encoder: (sklearn.preprocessing.OrdinalEncoder)\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    x (numpy.array): numpy.array of x values\n",
    "    y (numpy.array): numpy.array of y values\n",
    "    \"\"\"\n",
    "    \n",
    "    x= np.array(df.apply(lambda row: np.ndarray.flatten(row[images]),axis=1).to_list())\n",
    "    y= encoder.transform(df[target].to_numpy().reshape(-1,1)).flatten() \n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_image_database(path,target):\n",
    "    \"\"\"    Build a pandas dataframe with target class and access path to images.\n",
    "\n",
    "    Parameters:\n",
    "        - path (Path): Path pattern to read csv file containing images information\n",
    "        - target(str): The second column to extract from the file\n",
    "\n",
    "    Return:\n",
    "        A pandas dataframe,\n",
    "    -------\n",
    "    \"\"\"\n",
    "    #Load file\n",
    "    _df= pd.read_csv(path,\n",
    "            names=[\"all\"],\n",
    "        )\n",
    "    #Recover data\n",
    "    _df[\"image_id\"]=_df[\"all\"].apply(lambda x: x.split(' ')[0])\n",
    "    _df[target]=_df[\"all\"].apply(lambda x: ' '.join(x.split(' ')[1:]))\n",
    "    _df[target].unique()\n",
    "\n",
    "    #Create path\n",
    "    _df[\"path\"]= _df['image_id'].apply( lambda x: DATA_DIR/\"images\"/(x+'.jpg')) \n",
    "    \n",
    "    return _df.drop(columns=[\"all\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image(df,row,target):\n",
    "    \"\"\"show the image in the ligne row and the associated target column\n",
    "\n",
    "    Args:\n",
    "        df (pandas.dataFrame): the dataframe of images\n",
    "        row (int): the index of the row\n",
    "        target (string): the column name of the associated label\n",
    "    Return\n",
    "    ------\n",
    "    None\n",
    "    \"\"\"\n",
    "\n",
    "    assert target in df.columns, f\"Column {target} not found in dataframe\"\n",
    "    assert 'path' in df.columns, f\"Column path doens't not exit in dataframe\"\n",
    "    _img = plt.imread(df.loc[row,'path'])\n",
    "    plt.imshow(_img)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_images(images,model,classes_names=None):\n",
    "    \"\"\"Classify images through a tensorflow model.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    \n",
    "    images(np.array): set of images to classify\n",
    "    model (tensorflow.keras.Model): tensorflow/keras model\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    predicted classes \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    classes = model.predict(images).astype(int)\n",
    "    if classes_names is not None:\n",
    "        classes = classes_names[list(classes)]\n",
    "    return classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model ,saving_dir=MODELS_DIR,basename=TARGET_NAME,append_time=False):\n",
    "    \"\"\"Save tf/Keras model in saving_dir folder\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model (tf/Keras model): model to be saved\n",
    "    saving_dir (path): location to save model file\n",
    "    basename (str): the basename of the model\n",
    "    append_time (bool): indicate if the time will be append to the basename\n",
    "    \"\"\"\n",
    "    model_name = f\"{basename}{'_' + datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S') if append_time   else ''}\"\n",
    "    #use the same extension to keep harmony\n",
    "    with open(f\"{saving_dir}/svms/{model_name}.h5\",\"wb\") as file:\n",
    "        pickle.dump(model,file)\n",
    "    return model_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read train & test file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = build_image_database(DATA_DIR/DATA_TRAIN_FILE,TARGET_NAME)\n",
    "test_df = build_image_database(DATA_DIR/DATA_TEST_FILE,TARGET_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Previous the dataframe \n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# View some images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(train_df, np.random.randint(0,train_df.shape[0]), TARGET_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(test_df,np.random.randint(0,test_df.shape[0]),TARGET_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resize Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Resize train images\n",
    "train_df['resized_image'] = train_df.apply(\n",
    "        lambda r: load_resize_image(r['path'],IMAGE_HEIGHT,IMAGE_WIDTH),\n",
    "        axis=1)\n",
    "#Resize test images\n",
    "test_df['resized_image'] = test_df.apply(\n",
    "    lambda r: load_resize_image(r['path'],IMAGE_HEIGHT,IMAGE_WIDTH),\n",
    "    axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split dataset into x and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create an Ordinal encoder to encode target\n",
    "encoder = OrdinalEncoder(handle_unknown=\"use_encoded_value\",unknown_value=-99)\n",
    "encoder.fit(train_df[TARGET_NAME].to_numpy().reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,y_train = build_x_and_y(train_df,TARGET_NAME,'resized_image',encoder)\n",
    "X_test,y_test = build_x_and_y(test_df,TARGET_NAME,'resized_image',encoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build & train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model  = svm.SVC(kernel=\"poly\",probability=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_names = np.array(encoder.categories_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#try some predictions\n",
    "classify_images(X_test[10:20],model,classes_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute the mean accuracy  \n",
    "svm_accuracy = model.score(X_test,y_test)\n",
    "svm_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = save_model(model,MODELS_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(MODELS_DIR/\"classes\"/f\"{model_name}.yaml\",\"w\") as classe_file:\n",
    "    yaml.dump(list(classes_names),classe_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare SVM with Neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neural_model = tf.keras.models.load_model(MODELS_DIR/f\"neural_networks/{model_name}.h5\")\n",
    "x= np.array(test_df[\"resized_image\"].to_list())\n",
    "neural_prediction = neural_model.predict(x).argmax(axis=1)\n",
    "neural_accuracy = np.mean(y_test==neural_prediction)\n",
    "neural_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\"\"\n",
    "======Accuracy=====\n",
    "Neural network: {round(neural_accuracy,2)},\n",
    "SVC: {round(svm_accuracy,2)}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c0c62eb8809ce627d066c8fbd0f39db2e3615da8e58a6548a8d5314d7610383d"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
